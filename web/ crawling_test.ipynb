{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "source = requests.get(\"https://www.naver.com/\").text\n",
    "soup = BeautifulSoup(source, \"html.parser\")\n",
    "hotKeys = soup.select(\"span.keyword\")\n",
    "\n",
    "index = 0\n",
    "for key in hotKeys:\n",
    "    index +=1\n",
    "    print(str(index) + \", \" + key.text)\n",
    "    if index >=20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "with open(\"ex01.html\") as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위 코드와 동일\n",
    "fp = open(\"ex01.html\")\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>Web Crawling Example</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p>a</p>\n",
       "<p>b</p>\n",
       "<p>c</p>\n",
       "</div>\n",
       "<div class=\"ex_class\">\n",
       "<p>1</p>\n",
       "<p>2</p>\n",
       "<p>3</p>\n",
       "</div>\n",
       "<div id=\"ex_id\">\n",
       "<p>X</p>\n",
       "<p>Y</p>\n",
       "<p>Z</p>\n",
       "</div>\n",
       "<h1>This is a heading.</h1>\n",
       "<p>this is paragragh.</p>\n",
       "<p>this is another paragragh.</p>\n",
       "<a class=\"a\" href=\"https://www.naver.com\">\n",
       "            Naver\n",
       "        </a>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "with urllib.request.urlopen(\"https://www.naver.com\") as response:\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p>a</p>\n",
      "<p>b</p>\n",
      "<p>c</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "fp = open(\"ex01.html\")\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "first_div = soup.find(\"div\")\n",
    "print(first_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div>\n",
      "<p>a</p>\n",
      "<p>b</p>\n",
      "<p>c</p>\n",
      "</div>, <div class=\"ex_class\">\n",
      "<p>1</p>\n",
      "<p>2</p>\n",
      "<p>3</p>\n",
      "</div>, <div id=\"ex_id\">\n",
      "<p>X</p>\n",
      "<p>Y</p>\n",
      "<p>Z</p>\n",
      "</div>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div id=\"ex_id\">\n",
       "<p>X</p>\n",
       "<p>Y</p>\n",
       "<p>Z</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_divs = soup.find_all(\"div\")\n",
    "print(all_divs)\n",
    "soup.find_all(\"div\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"ex_id\">\n",
      "<p>X</p>\n",
      "<p>Y</p>\n",
      "<p>Z</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "ex_id_divs = soup.find('div',{'id':'ex_id'})\n",
    "print(ex_id_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"ex_class\">\n",
      "<p>1</p>\n",
      "<p>2</p>\n",
      "<p>3</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "result = soup.find('div', class_ = 'ex_class')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"ex_class\">\n",
      "<p>1</p>\n",
      "<p>2</p>\n",
      "<p>3</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "class_res = soup.find('div', {'class':'ex_class'})\n",
    "print(class_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>X</p>, <p>Y</p>, <p>Z</p>]\n"
     ]
    }
   ],
   "source": [
    "ex_id_divs= soup.find(\"div\", {\"id\":\"ex_id\"})\n",
    "all_ps_in_ex_id_divs = ex_id_divs.find_all(\"p\")\n",
    "print(all_ps_in_ex_id_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p>a</p>\n",
      "<p>b</p>\n",
      "<p>c</p>\n",
      "</div>\n",
      "\n",
      "<div class=\"ex_class\">\n",
      "<p>1</p>\n",
      "<p>2</p>\n",
      "<p>3</p>\n",
      "</div>\n",
      "\n",
      "<div id=\"ex_id\">\n",
      "<p>X</p>\n",
      "<p>Y</p>\n",
      "<p>Z</p>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_divs = soup.find_all('div')\n",
    "for each_div in all_divs:\n",
    "    print(each_div)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<p>a</p>\n",
       "<p>b</p>\n",
       "<p>c</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na\\nb\\nc\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_divs[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a\n",
      "b\n",
      "c\n",
      "\n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "\n",
      "X\n",
      "Y\n",
      "Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for divs_item in all_divs:\n",
    "    print(divs_item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(class_='ex_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLT\n",
      "Fried Bologna\n",
      "Woodland Mushroom\n",
      "Roast Beef\n",
      "PB&L\n",
      "Belgian Chicken Curry Salad\n",
      "Lobster Roll\n",
      "Smoked Salmon Salad\n",
      "Atomica Cemitas\n",
      "Grilled Laughing Bird Shrimp and Fried Po’ Boy\n",
      "Ham and Raclette Panino\n",
      "Breaded Steak\n",
      "The Hawkeye\n",
      "Chicken Dip\n",
      "Wild Boar Sloppy Joe\n",
      "Meatball Sub\n",
      "Corned Beef\n",
      "Turkey Club\n",
      "Falafel\n",
      "Crab Cake\n",
      "Chicken Schnitzel\n",
      "Shawarma\n",
      "Toasted Pimiento Cheese\n",
      "Vegetarian Panino\n",
      "Cali Chèvre\n",
      "Pastrami\n",
      "The Fredo\n",
      "Smoked Ham\n",
      "Jibarito\n",
      "Shaved Prime Rib\n",
      "Serrano Ham and Manchego Cheese\n",
      "Tuna Salad\n",
      "Paramount Reuben\n",
      "The Istanbul\n",
      "B.A.D.\n",
      "Duck Confit and Mozzarella\n",
      "Croque Monsieur\n",
      "Green Garbanzo\n",
      "The Hen House\n",
      "Tuscan Chicken\n",
      "The Marty \n",
      "Whitefish\n",
      "Oat Bread, Pecan Butter, and Fruit Jam\n",
      "Cauliflower Melt\n",
      "Cubana\n",
      "Kufta\n",
      "Debbie’s Egg Salad\n",
      "Beef Curry\n",
      "Le Végétarien\n",
      "The Gatsby\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "with urllib.request.urlopen(\"https://goo.gl/wAtv1s\") as response:\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "re = []\n",
    "re2 = []\n",
    "cl = soup.find_all('div', {'class':'sammyListing'})\n",
    "\n",
    "for result in cl:\n",
    "    re = result.find(\"b\").get_text()\n",
    "    print(re)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$10. 2109 W. Chicago Ave., 773-772-0406, theoldoaktap.com\n"
     ]
    }
   ],
   "source": [
    "with urllib.request.urlopen(\"https://www.chicagomag.com/Chicago-Magazine/November-2012/Best-Sandwiches-in-Chicago-Old-Oak-Tap-BLT/\") as response:\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "cl2 = soup.find('p', {'class':'addy'})\n",
    "result2 = cl2.find(\"em\")\n",
    "print(result2.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
